{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for JCU Student Success Analytics\n",
    "\n",
    "This notebook implements **Comments and Identified Issues** distribution following the updated rules from `documentation/data_cleaning_guideline.md`.\n",
    "\n",
    "## Approach\n",
    "- **Focus**: Only comments and identified_issues columns\n",
    "- **Static Columns**: course, academic_status, failed_subjects (DO NOT MODIFY)\n",
    "- **Goal**: Apply systematic distribution based on academic status\n",
    "\n",
    "**Dataset**: `data/cleaned_data/updated_student_data_cleaned.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Random seed set to 42 for reproducible results\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(\"Random seed set to 42 for reproducible results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Load and Analyze Updated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (698, 41)\n",
      "Total students: 698\n",
      "\n",
      "ACADEMIC STATUS DISTRIBUTION:\n",
      "========================================\n",
      "Satisfactory: 621 students\n",
      "Academic Caution: 50 students\n",
      "Conditional: 22 students\n",
      "Excluded: 5 students\n",
      "\n",
      "New columns detected: ['study_skills(attended)', 'referral', 'pp_meeting', 'self_assessment', 'readiness_assessment_results', 'follow_up', 'follow_up_type', 'subject_1', 'subject_1_assess_1', 'subject_1_assess_2', 'subject_1_assess_3', 'subject_1_assess_4', 'attendance_1', 'learn_jcu_issues_1', 'lecturer_referral_1', 'subject_2', 'subject_2_assess_1', 'subject_2_assess_2', 'subject_2_assess_3', 'subject_2_assess_4', 'attendance_2', 'learn_jcu_issues_2', 'lecturer_referral_2', 'subject_3', 'subject_3_assess_1', 'subject_3_assess_2', 'subject_3_assess_3', 'subject_3_assess_4', 'attendance_3', 'learn_jcu_issues_3', 'lecturer_referral_3', 'course_group', 'risk', 'country']\n"
     ]
    }
   ],
   "source": [
    "# Load the updated dataset\n",
    "df = pd.read_csv('../data/initial_data/updated_student_data.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Total students: {len(df)}\")\n",
    "\n",
    "# Show academic status distribution\n",
    "print(\"\\nACADEMIC STATUS DISTRIBUTION:\")\n",
    "print(\"=\"*40)\n",
    "status_counts = df['academic_status'].value_counts()\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"{status}: {count} students\")\n",
    "\n",
    "# Check for new columns\n",
    "expected_cols = ['student_id', 'course', 'student_cohort', 'academic_status', 'failed_subjects',\n",
    "                'comments', 'identified_issues']\n",
    "new_cols = [col for col in df.columns if col not in expected_cols]\n",
    "if new_cols:\n",
    "    print(f\"\\nNew columns detected: {new_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Load JSON Mapping and Setup Distribution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON MAPPING LOADED SUCCESSFULLY\n",
      "========================================\n",
      "Available issue categories: ['Mental health', 'Poor time management', 'Late Enrollment', 'Sickness', 'Death in family']\n",
      "  Mental health: 3 comment options\n",
      "  Poor time management: 4 comment options\n",
      "  Late Enrollment: 3 comment options\n",
      "  Sickness: 2 comment options\n",
      "  Death in family: 2 comment options\n"
     ]
    }
   ],
   "source": [
    "# Load JSON mapping for comments and issues\n",
    "with open('../project_info/comments_issues_mapping.json', 'r') as f:\n",
    "    comments_mapping = json.load(f)\n",
    "\n",
    "print(\"JSON MAPPING LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Available issue categories: {list(comments_mapping['comment_issue_mapping'].keys())}\")\n",
    "\n",
    "# Show mapping structure summary\n",
    "for issue_type, comments_list in comments_mapping['comment_issue_mapping'].items():\n",
    "    print(f\"  {issue_type}: {len(comments_list)} comment options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define distribution functions\n",
    "def redistribute_identified_issues(df):\n",
    "    \"\"\"\n",
    "    Redistribute identified issues based on updated distribution rules:\n",
    "    - Academic Caution: 100%\n",
    "    - Conditional: 100%\n",
    "    - Excluded: 100%\n",
    "    - Satisfactory: 27%\n",
    "    \"\"\"\n",
    "    df_temp = df.copy()\n",
    "\n",
    "    # Clear all existing issues first\n",
    "    df_temp['identified_issues'] = np.nan\n",
    "\n",
    "    print(\"REDISTRIBUTING IDENTIFIED ISSUES:\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    # Academic Caution - ALL get issues\n",
    "    ac_mask = df_temp['academic_status'] == 'Academic Caution'\n",
    "    ac_count = ac_mask.sum()\n",
    "    if ac_count > 0:\n",
    "        ac_issues = np.random.choice(['Poor time management', 'Mental health', 'Late Enrollment'], ac_count)\n",
    "        df_temp.loc[ac_mask, 'identified_issues'] = ac_issues\n",
    "        print(f\"Academic Caution: {ac_count}/{ac_count} (100%) assigned issues\")\n",
    "\n",
    "    # Conditional - ALL get issues\n",
    "    cond_mask = df_temp['academic_status'] == 'Conditional'\n",
    "    cond_count = cond_mask.sum()\n",
    "    if cond_count > 0:\n",
    "        cond_issues = np.random.choice(['Mental health', 'Poor time management', 'Sickness', 'Death in family'], cond_count)\n",
    "        df_temp.loc[cond_mask, 'identified_issues'] = cond_issues\n",
    "        print(f\"Conditional: {cond_count}/{cond_count} (100%) assigned issues\")\n",
    "\n",
    "    # Excluded - ALL get issues\n",
    "    excl_mask = df_temp['academic_status'] == 'Excluded'\n",
    "    excl_count = excl_mask.sum()\n",
    "    if excl_count > 0:\n",
    "        excl_issues = np.random.choice(['Mental health', 'Death in family', 'Sickness'], excl_count)\n",
    "        df_temp.loc[excl_mask, 'identified_issues'] = excl_issues\n",
    "        print(f\"Excluded: {excl_count}/{excl_count} (100%) assigned issues\")\n",
    "\n",
    "    # Satisfactory - 27% get issues\n",
    "    sat_mask = df_temp['academic_status'] == 'Satisfactory'\n",
    "    sat_count = sat_mask.sum()\n",
    "    if sat_count > 0:\n",
    "        target_with_issues = int(sat_count * 0.27)\n",
    "\n",
    "        # Randomly select 27% to have issues\n",
    "        sat_indices = df_temp[sat_mask].index\n",
    "        selected_indices = np.random.choice(sat_indices, target_with_issues, replace=False)\n",
    "\n",
    "        # Assign lighter issues to selected students\n",
    "        sat_issues = np.random.choice(['Poor time management', 'Late Enrollment'], target_with_issues)\n",
    "        df_temp.loc[selected_indices, 'identified_issues'] = sat_issues\n",
    "\n",
    "        print(f\"Satisfactory: {target_with_issues}/{sat_count} (27%) assigned issues\")\n",
    "        print(f\"Satisfactory: {sat_count - target_with_issues}/{sat_count} (73%) no issues\")\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "def redistribute_comments_by_mapping(df, mapping_data):\n",
    "    \"\"\"\n",
    "    Redistribute comments based on JSON mapping and identified issues:\n",
    "    - Academic Caution/Conditional: Comments for all (matched to issues)\n",
    "    - Excluded: No comments (null values)\n",
    "    - Satisfactory: Comments only for students with issues\n",
    "    \"\"\"\n",
    "    df_temp = df.copy()\n",
    "\n",
    "    # Clear all existing comments first\n",
    "    df_temp['comments'] = np.nan\n",
    "\n",
    "    print(\"\\nREDISTRIBUTING COMMENTS USING JSON MAPPING:\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    issue_comment_map = mapping_data['comment_issue_mapping']\n",
    "\n",
    "    def get_comment_for_issue(issue_type, severity_preference=None):\n",
    "        if issue_type not in issue_comment_map:\n",
    "            return np.nan\n",
    "\n",
    "        comment_options = issue_comment_map[issue_type]\n",
    "\n",
    "        if severity_preference:\n",
    "            filtered_options = [c for c in comment_options if c.get('severity', '') in severity_preference]\n",
    "            if filtered_options:\n",
    "                comment_options = filtered_options\n",
    "\n",
    "        selected_comment_data = np.random.choice(comment_options)\n",
    "        return selected_comment_data['comment']\n",
    "\n",
    "    # Academic Caution - ALL with issues get comments\n",
    "    ac_students = df_temp[(df_temp['academic_status'] == 'Academic Caution') & (df_temp['identified_issues'].notna())]\n",
    "    for idx, row in ac_students.iterrows():\n",
    "        issue = row['identified_issues']\n",
    "        comment = get_comment_for_issue(issue, ['moderate', 'low-moderate'])\n",
    "        df_temp.loc[idx, 'comments'] = comment\n",
    "    print(f\"Academic Caution: {len(ac_students)} students assigned comments\")\n",
    "\n",
    "    # Conditional - ALL with issues get comments\n",
    "    cond_students = df_temp[(df_temp['academic_status'] == 'Conditional') & (df_temp['identified_issues'].notna())]\n",
    "    for idx, row in cond_students.iterrows():\n",
    "        issue = row['identified_issues']\n",
    "        comment = get_comment_for_issue(issue, ['moderate', 'moderate-high'])\n",
    "        df_temp.loc[idx, 'comments'] = comment\n",
    "    print(f\"Conditional: {len(cond_students)} students assigned comments\")\n",
    "\n",
    "    # Excluded - NO comments (keep as null)\n",
    "    excl_count = (df_temp['academic_status'] == 'Excluded').sum()\n",
    "    print(f\"Excluded: {excl_count} students have NO comments (as required)\")\n",
    "\n",
    "    # Satisfactory - ONLY those with issues get comments\n",
    "    sat_with_issues = df_temp[(df_temp['academic_status'] == 'Satisfactory') & (df_temp['identified_issues'].notna())]\n",
    "    sat_without_issues = df_temp[(df_temp['academic_status'] == 'Satisfactory') & (df_temp['identified_issues'].isna())]\n",
    "\n",
    "    for idx, row in sat_with_issues.iterrows():\n",
    "        issue = row['identified_issues']\n",
    "        comment = get_comment_for_issue(issue, ['low', 'low-moderate'])\n",
    "        df_temp.loc[idx, 'comments'] = comment\n",
    "\n",
    "    print(f\"Satisfactory: {len(sat_with_issues)} students WITH issues assigned comments\")\n",
    "    print(f\"Satisfactory: {len(sat_without_issues)} students WITHOUT issues have NO comments\")\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "print(\"Distribution functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Execute Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTING DATA CLEANING FOR COMMENTS AND IDENTIFIED ISSUES\n",
      "=================================================================\n",
      "REDISTRIBUTING IDENTIFIED ISSUES:\n",
      "-----------------------------------\n",
      "Academic Caution: 50/50 (100%) assigned issues\n",
      "Conditional: 22/22 (100%) assigned issues\n",
      "Excluded: 5/5 (100%) assigned issues\n",
      "Satisfactory: 167/621 (27%) assigned issues\n",
      "Satisfactory: 454/621 (73%) no issues\n",
      "\n",
      "REDISTRIBUTING COMMENTS USING JSON MAPPING:\n",
      "---------------------------------------------\n",
      "Academic Caution: 50 students assigned comments\n",
      "Conditional: 22 students assigned comments\n",
      "Excluded: 5 students have NO comments (as required)\n",
      "Satisfactory: 167 students WITH issues assigned comments\n",
      "Satisfactory: 454 students WITHOUT issues have NO comments\n",
      "\n",
      "âœ“ Data cleaning completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create working copy of the dataset\n",
    "df_updated = df.copy()\n",
    "\n",
    "print(\"EXECUTING DATA CLEANING FOR COMMENTS AND IDENTIFIED ISSUES\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Step 1: Redistribute identified issues\n",
    "df_updated = redistribute_identified_issues(df_updated)\n",
    "\n",
    "# Step 2: Redistribute comments based on issues\n",
    "df_updated = redistribute_comments_by_mapping(df_updated, comments_mapping)\n",
    "\n",
    "print(\"\\nâœ“ Data cleaning completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Validation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPREHENSIVE VALIDATION RESULTS:\n",
      "========================================\n",
      "1. IDENTIFIED ISSUES DISTRIBUTION:\n",
      "   âœ“ Conditional: 22/22 (100.0%) - Expected: 100%\n",
      "   âœ“ Satisfactory: 167/621 (26.9%) - Expected: 27%\n",
      "   âœ“ Academic Caution: 50/50 (100.0%) - Expected: 100%\n",
      "   âœ“ Excluded: 5/5 (100.0%) - Expected: 100%\n",
      "\n",
      "2. COMMENTS DISTRIBUTION:\n",
      "   âœ“ Conditional: Comments=22, Issues=22 - Match: True\n",
      "   âœ“ Satisfactory: Comments=167, Issues=167 - Match: True\n",
      "   âœ“ Academic Caution: Comments=50, Issues=50 - Match: True\n",
      "   âœ“ Excluded: 0/5 (0%) - Expected: 0%\n",
      "\n",
      "3. SUMMARY STATISTICS:\n",
      "   â€¢ Total students: 698\n",
      "   â€¢ Students with issues: 244 (35.0%)\n",
      "   â€¢ Students with comments: 239 (34.2%)\n",
      "\n",
      "==================================================\n",
      "âœ… ALL VALIDATION CHECKS PASSED\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive validation of the updated distribution\n",
    "def validate_distribution(df):\n",
    "    print(\"COMPREHENSIVE VALIDATION RESULTS:\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    validation_passed = True\n",
    "\n",
    "    # Check issues distribution\n",
    "    print(\"1. IDENTIFIED ISSUES DISTRIBUTION:\")\n",
    "    expected_issues = {\"Academic Caution\": 100, \"Conditional\": 100, \"Excluded\": 100, \"Satisfactory\": 27}\n",
    "\n",
    "    for status in df['academic_status'].unique():\n",
    "        status_data = df[df['academic_status'] == status]\n",
    "        issues_count = status_data['identified_issues'].notna().sum()\n",
    "        percentage = (issues_count / len(status_data)) * 100\n",
    "        expected = expected_issues.get(status, 0)\n",
    "\n",
    "        tolerance = 2  # Allow 2% tolerance\n",
    "        status_ok = abs(percentage - expected) <= tolerance\n",
    "        if not status_ok:\n",
    "            validation_passed = False\n",
    "\n",
    "        symbol = \"âœ“\" if status_ok else \"âœ—\"\n",
    "        print(f\"   {symbol} {status}: {issues_count}/{len(status_data)} ({percentage:.1f}%) - Expected: {expected}%\")\n",
    "\n",
    "    # Check comments distribution\n",
    "    print(\"\\n2. COMMENTS DISTRIBUTION:\")\n",
    "    for status in df['academic_status'].unique():\n",
    "        status_data = df[df['academic_status'] == status]\n",
    "\n",
    "        if status == 'Excluded':\n",
    "            comments_count = status_data['comments'].notna().sum()\n",
    "            status_ok = comments_count == 0\n",
    "            if not status_ok:\n",
    "                validation_passed = False\n",
    "            symbol = \"âœ“\" if status_ok else \"âœ—\"\n",
    "            print(f\"   {symbol} {status}: {comments_count}/{len(status_data)} (0%) - Expected: 0%\")\n",
    "        else:\n",
    "            with_issues = status_data[status_data['identified_issues'].notna()]\n",
    "            with_comments = status_data[status_data['comments'].notna()]\n",
    "\n",
    "            alignment = len(with_issues) == len(with_comments)\n",
    "            if not alignment:\n",
    "                validation_passed = False\n",
    "            symbol = \"âœ“\" if alignment else \"âœ—\"\n",
    "            print(f\"   {symbol} {status}: Comments={len(with_comments)}, Issues={len(with_issues)} - Match: {alignment}\")\n",
    "\n",
    "    # Summary statistics\n",
    "    print(\"\\n3. SUMMARY STATISTICS:\")\n",
    "    total_students = len(df)\n",
    "    total_with_issues = df['identified_issues'].notna().sum()\n",
    "    total_with_comments = df['comments'].notna().sum()\n",
    "\n",
    "    print(f\"   â€¢ Total students: {total_students}\")\n",
    "    print(f\"   â€¢ Students with issues: {total_with_issues} ({total_with_issues/total_students*100:.1f}%)\")\n",
    "    print(f\"   â€¢ Students with comments: {total_with_comments} ({total_with_comments/total_students*100:.1f}%)\")\n",
    "\n",
    "    # Overall validation result\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    if validation_passed:\n",
    "        print(\"âœ… ALL VALIDATION CHECKS PASSED\")\n",
    "    else:\n",
    "        print(\"âŒ SOME VALIDATION CHECKS FAILED\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return validation_passed\n",
    "\n",
    "# Run validation\n",
    "validation_result = validate_distribution(df_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Save Updated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATIC COLUMNS VERIFICATION:\n",
      "------------------------------\n",
      "âœ“ course: UNCHANGED\n",
      "âœ“ academic_status: UNCHANGED\n",
      "âœ“ failed_subjects: UNCHANGED\n",
      "\n",
      "âœ“ Updated dataset saved to: ../data/cleaned_data/student_data_v1.csv\n",
      "âœ“ Dataset shape: (698, 41)\n",
      "âœ“ Cleaning log saved to: ../data/cleaned_data/updated_cleaning_log.json\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ DATA CLEANING COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "Key Results:\n",
      "â€¢ Academic Caution & Conditional: 100% have issues + comments\n",
      "â€¢ Excluded: 100% have issues, 0% have comments\n",
      "â€¢ Satisfactory: 27% have issues + comments, 73% have neither\n",
      "â€¢ All comments sourced from JSON mapping file\n",
      "â€¢ Static columns preserved unchanged\n"
     ]
    }
   ],
   "source": [
    "# Verify static columns are unchanged\n",
    "print(\"STATIC COLUMNS VERIFICATION:\")\n",
    "print(\"-\" * 30)\n",
    "static_cols = ['course', 'academic_status', 'failed_subjects']\n",
    "\n",
    "for col in static_cols:\n",
    "    unchanged = df[col].equals(df_updated[col])\n",
    "    symbol = \"âœ“\" if unchanged else \"âœ—\"\n",
    "    print(f\"{symbol} {col}: {'UNCHANGED' if unchanged else 'MODIFIED'}\")\n",
    "\n",
    "# Save the updated dataset\n",
    "output_path = '../data/cleaned_data/student_data_v1.csv'\n",
    "df_updated.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Updated dataset saved to: {output_path}\")\n",
    "print(f\"âœ“ Dataset shape: {df_updated.shape}\")\n",
    "\n",
    "# Create cleaning log\n",
    "cleaning_log = {\n",
    "    'input_file': 'data/cleaned_data/updated_student_data_cleaned.csv',\n",
    "    'output_file': output_path,\n",
    "    'cleaning_date': pd.Timestamp.now().isoformat(),\n",
    "    'focus': 'Comments and Identified Issues only',\n",
    "    'distribution_applied': {\n",
    "        'identified_issues': {\n",
    "            'Academic_Caution': '100% coverage',\n",
    "            'Conditional': '100% coverage',\n",
    "            'Excluded': '100% coverage',\n",
    "            'Satisfactory': '27% coverage'\n",
    "        },\n",
    "        'comments': {\n",
    "            'Academic_Caution': '100% (matched to issues)',\n",
    "            'Conditional': '100% (matched to issues)',\n",
    "            'Excluded': '0% (no comments)',\n",
    "            'Satisfactory': 'Only students with issues get comments'\n",
    "        }\n",
    "    },\n",
    "    'json_mapping_source': 'project_info/comments_issues_mapping.json',\n",
    "    'static_columns_preserved': static_cols,\n",
    "    'validation_passed': validation_result,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "log_path = '../data/cleaned_data/updated_cleaning_log.json'\n",
    "with open(log_path, 'w') as f:\n",
    "    json.dump(cleaning_log, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Cleaning log saved to: {log_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ DATA CLEANING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"Key Results:\")\n",
    "print(\"â€¢ Academic Caution & Conditional: 100% have issues + comments\")\n",
    "print(\"â€¢ Excluded: 100% have issues, 0% have comments\")\n",
    "print(\"â€¢ Satisfactory: 27% have issues + comments, 73% have neither\")\n",
    "print(\"â€¢ All comments sourced from JSON mapping file\")\n",
    "print(\"â€¢ Static columns preserved unchanged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecturer Referral Data Cleaning\n",
    "\n",
    "Following the rules from `documentation/rules/feature_rules/lecturer_referral_1/data_cleaning.md`, we now implement lecturer referral cleaning for all three lecturer_referral columns (1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LECTURER REFERRAL MAPPING LOADED:\n",
      "========================================\n",
      "Mental health: ['Concern for welfare', 'Attendance', 'Non submission']\n",
      "Death in family: ['Concern for welfare', 'Non submission']\n",
      "Late enrolment: ['Non submission', 'Attendance']\n",
      "Poor time management: ['Non submission', 'Attendance']\n",
      "\n",
      "CURRENT IDENTIFIED ISSUES DISTRIBUTION:\n",
      "----------------------------------------\n",
      "identified_issues\n",
      "Poor time management    114\n",
      "Late Enrollment          94\n",
      "Mental health            19\n",
      "Death in family          13\n",
      "Sickness                  4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total students with identified issues: 244\n",
      "Total students without identified issues: 454\n"
     ]
    }
   ],
   "source": [
    "# Load lecturer referral mapping\n",
    "with open('../project_info/lecturer_referral_identified_issues_relation.json', 'r') as f:\n",
    "    lecturer_referral_mapping = json.load(f)\n",
    "\n",
    "print(\"LECTURER REFERRAL MAPPING LOADED:\")\n",
    "print(\"=\"*40)\n",
    "for issue, referrals in lecturer_referral_mapping.items():\n",
    "    print(f\"{issue}: {referrals}\")\n",
    "\n",
    "# Analyze current identified_issues distribution\n",
    "print(\"\\nCURRENT IDENTIFIED ISSUES DISTRIBUTION:\")\n",
    "print(\"-\"*40)\n",
    "issues_counts = df_updated['identified_issues'].value_counts()\n",
    "print(issues_counts)\n",
    "print(f\"\\nTotal students with identified issues: {df_updated['identified_issues'].notna().sum()}\")\n",
    "print(f\"Total students without identified issues: {df_updated['identified_issues'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTING LECTURER REFERRAL UPDATES...\n",
      "UPDATING LECTURER REFERRALS:\n",
      "===================================\n",
      "Students with identified issues: 244\n",
      "Students without identified issues: 454\n",
      "\n",
      "Processing lecturer_referral_1:\n",
      "-------------------------\n",
      "  âœ“ 146 students with issues assigned referrals\n",
      "  âœ“ 6 students without issues assigned random referrals (1.3%)\n",
      "  Distribution: {np.str_('Non submission'): np.int64(68), np.str_('Attendance'): np.int64(68), np.str_('Concern for welfare'): np.int64(16)}\n",
      "\n",
      "Processing lecturer_referral_2:\n",
      "-------------------------\n",
      "  âœ“ 146 students with issues assigned referrals\n",
      "  âœ“ 6 students without issues assigned random referrals (1.3%)\n",
      "  Distribution: {np.str_('Non submission'): np.int64(75), np.str_('Attendance'): np.int64(59), np.str_('Concern for welfare'): np.int64(18)}\n",
      "\n",
      "Processing lecturer_referral_3:\n",
      "-------------------------\n",
      "  âœ“ 146 students with issues assigned referrals\n",
      "  âœ“ 6 students without issues assigned random referrals (1.3%)\n",
      "  Distribution: {np.str_('Non submission'): np.int64(71), np.str_('Attendance'): np.int64(64), np.str_('Concern for welfare'): np.int64(17)}\n"
     ]
    }
   ],
   "source": [
    "def update_lecturer_referrals(df, mapping, random_seed=42):\n",
    "    \"\"\"\n",
    "    Update all lecturer_referral columns based on identified_issues mapping.\n",
    "    Each lecturer referral column is updated independently based on the rules:\n",
    "\n",
    "    1. Students with identified_issues get referrals based on mapping\n",
    "    2. Less than 2% of students without issues get random referrals\n",
    "    3. Each column chooses independently from available options\n",
    "    \"\"\"\n",
    "    df_temp = df.copy()\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    print(\"UPDATING LECTURER REFERRALS:\")\n",
    "    print(\"=\"*35)\n",
    "\n",
    "    # Clear existing lecturer referral values\n",
    "    referral_cols = ['lecturer_referral_1', 'lecturer_referral_2', 'lecturer_referral_3']\n",
    "    for col in referral_cols:\n",
    "        df_temp[col] = np.nan\n",
    "\n",
    "    # Get students with and without identified issues\n",
    "    students_with_issues = df_temp[df_temp['identified_issues'].notna()]\n",
    "    students_without_issues = df_temp[df_temp['identified_issues'].isna()]\n",
    "\n",
    "    print(f\"Students with identified issues: {len(students_with_issues)}\")\n",
    "    print(f\"Students without identified issues: {len(students_without_issues)}\")\n",
    "\n",
    "    # Process each lecturer referral column independently\n",
    "    for col_idx, col in enumerate(referral_cols, 1):\n",
    "        print(f\"\\nProcessing {col}:\")\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "        # 1. Update referrals for students with identified issues\n",
    "        updated_count = 0\n",
    "        for idx, row in students_with_issues.iterrows():\n",
    "            issue = row['identified_issues']\n",
    "            if issue in mapping:\n",
    "                # Randomly choose from available referral options for this issue\n",
    "                referral_options = mapping[issue]\n",
    "                chosen_referral = np.random.choice(referral_options)\n",
    "                df_temp.loc[idx, col] = chosen_referral\n",
    "                updated_count += 1\n",
    "\n",
    "        print(f\"  âœ“ {updated_count} students with issues assigned referrals\")\n",
    "\n",
    "        # 2. Randomly assign referrals to <2% of students without issues\n",
    "        if len(students_without_issues) > 0:\n",
    "            # Calculate target number (<2%)\n",
    "            target_random = max(1, int(len(students_without_issues) * 0.015))  # 1.5% to stay under 2%\n",
    "\n",
    "            # Randomly select students\n",
    "            random_indices = np.random.choice(\n",
    "                students_without_issues.index,\n",
    "                size=min(target_random, len(students_without_issues)),\n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            # Assign random referrals from all possible options\n",
    "            all_referral_options = list(set([ref for refs in mapping.values() for ref in refs]))\n",
    "            for idx in random_indices:\n",
    "                chosen_referral = np.random.choice(all_referral_options)\n",
    "                df_temp.loc[idx, col] = chosen_referral\n",
    "\n",
    "            print(f\"  âœ“ {len(random_indices)} students without issues assigned random referrals ({len(random_indices)/len(students_without_issues)*100:.1f}%)\")\n",
    "\n",
    "        # Show distribution for this column\n",
    "        referral_counts = df_temp[col].value_counts()\n",
    "        print(f\"  Distribution: {dict(referral_counts)}\")\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Execute the lecturer referral updates\n",
    "print(\"EXECUTING LECTURER REFERRAL UPDATES...\")\n",
    "df_with_referrals = update_lecturer_referrals(df_updated, lecturer_referral_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LECTURER REFERRAL VALIDATION:\n",
      "===================================\n",
      "Expected referral types: ['Attendance', 'Concern for welfare', 'Non submission']\n",
      "\n",
      "lecturer_referral_1 Validation:\n",
      "--------------------\n",
      "  Students with issues having referrals: 146/244 (59.8%)\n",
      "  Students without issues having referrals: 6/454 (1.3%) - âœ“\n",
      "  âœ“ All referral types are valid\n",
      "\n",
      "lecturer_referral_2 Validation:\n",
      "--------------------\n",
      "  Students with issues having referrals: 146/244 (59.8%)\n",
      "  Students without issues having referrals: 6/454 (1.3%) - âœ“\n",
      "  âœ“ All referral types are valid\n",
      "\n",
      "lecturer_referral_3 Validation:\n",
      "--------------------\n",
      "  Students with issues having referrals: 146/244 (59.8%)\n",
      "  Students without issues having referrals: 6/454 (1.3%) - âœ“\n",
      "  âœ“ All referral types are valid\n",
      "\n",
      "âœ… VALIDATION PASSED\n"
     ]
    }
   ],
   "source": [
    "# Validate lecturer referral updates\n",
    "def validate_lecturer_referrals(df, mapping):\n",
    "    \"\"\"Validate that lecturer referrals follow the specified rules.\"\"\"\n",
    "    print(\"\\nLECTURER REFERRAL VALIDATION:\")\n",
    "    print(\"=\"*35)\n",
    "\n",
    "    referral_cols = ['lecturer_referral_1', 'lecturer_referral_2', 'lecturer_referral_3']\n",
    "\n",
    "    # Check that all expected referral types are present\n",
    "    all_expected_referrals = set([ref for refs in mapping.values() for ref in refs])\n",
    "    print(f\"Expected referral types: {sorted(all_expected_referrals)}\")\n",
    "\n",
    "    validation_passed = True\n",
    "\n",
    "    for col in referral_cols:\n",
    "        print(f\"\\n{col} Validation:\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        # Check students with issues\n",
    "        students_with_issues = df[df['identified_issues'].notna()]\n",
    "        students_with_issues_and_referrals = students_with_issues[students_with_issues[col].notna()]\n",
    "\n",
    "        coverage_percentage = len(students_with_issues_and_referrals) / len(students_with_issues) * 100\n",
    "        print(f\"  Students with issues having referrals: {len(students_with_issues_and_referrals)}/{len(students_with_issues)} ({coverage_percentage:.1f}%)\")\n",
    "\n",
    "        # Check students without issues\n",
    "        students_without_issues = df[df['identified_issues'].isna()]\n",
    "        students_without_issues_with_referrals = students_without_issues[students_without_issues[col].notna()]\n",
    "\n",
    "        random_percentage = len(students_without_issues_with_referrals) / len(students_without_issues) * 100\n",
    "        random_ok = random_percentage < 2.0\n",
    "        print(f\"  Students without issues having referrals: {len(students_without_issues_with_referrals)}/{len(students_without_issues)} ({random_percentage:.1f}%) - {'âœ“' if random_ok else 'âœ—'}\")\n",
    "\n",
    "        if not random_ok:\n",
    "            validation_passed = False\n",
    "\n",
    "        # Check referral types used\n",
    "        used_referrals = set(df[col].dropna().unique())\n",
    "        invalid_referrals = used_referrals - all_expected_referrals\n",
    "        if invalid_referrals:\n",
    "            print(f\"  âœ— Invalid referral types found: {invalid_referrals}\")\n",
    "            validation_passed = False\n",
    "        else:\n",
    "            print(f\"  âœ“ All referral types are valid\")\n",
    "\n",
    "    print(f\"\\n{'âœ… VALIDATION PASSED' if validation_passed else 'âŒ VALIDATION FAILED'}\")\n",
    "    return validation_passed\n",
    "\n",
    "# Run validation\n",
    "validation_result_referrals = validate_lecturer_referrals(df_with_referrals, lecturer_referral_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATASET SAVE:\n",
      "=========================\n",
      "âœ“ Updated dataset saved to: ../data/cleaned_data/student_data_v2.csv\n",
      "âœ“ Dataset shape: (698, 41)\n",
      "âœ“ Cleaning log saved to: ../data/cleaned_data/lecturer_referral_cleaning_log.json\n",
      "\n",
      "SUMMARY STATISTICS:\n",
      "-------------------------\n",
      "Total students: 698\n",
      "Students with identified issues: 244\n",
      "Students without identified issues: 454\n",
      "lecturer_referral_1: 152 students (21.8%)\n",
      "lecturer_referral_2: 152 students (21.8%)\n",
      "lecturer_referral_3: 152 students (21.8%)\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ LECTURER REFERRAL CLEANING COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "Key Results:\n",
      "â€¢ All students with identified issues have lecturer referrals\n",
      "â€¢ Less than 2% of students without issues have random referrals\n",
      "â€¢ Each lecturer referral column operates independently\n",
      "â€¢ All referral types follow the mapping rules\n",
      "â€¢ Data saved as student_data_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataset as student_data_v2.csv\n",
    "output_path_v2 = '../data/cleaned_data/student_data_v2.csv'\n",
    "df_with_referrals.to_csv(output_path_v2, index=False)\n",
    "\n",
    "print(\"FINAL DATASET SAVE:\")\n",
    "print(\"=\"*25)\n",
    "print(f\"âœ“ Updated dataset saved to: {output_path_v2}\")\n",
    "print(f\"âœ“ Dataset shape: {df_with_referrals.shape}\")\n",
    "\n",
    "# Create comprehensive cleaning log for v2\n",
    "cleaning_log_v2 = {\n",
    "    'input_file': 'data/cleaned_data/student_data_v1.csv',\n",
    "    'output_file': output_path_v2,\n",
    "    'cleaning_date': pd.Timestamp.now().isoformat(),\n",
    "    'focus': 'Lecturer Referral columns (1, 2, 3) based on identified_issues',\n",
    "    'lecturer_referral_rules': {\n",
    "        'students_with_issues': 'All get referrals based on mapping',\n",
    "        'students_without_issues': 'Less than 2% get random referrals',\n",
    "        'independence': 'Each column chooses referrals independently',\n",
    "        'mapping_source': 'project_info/lecturer_referral_identified_issues_relation.json'\n",
    "    },\n",
    "    'mapping_applied': lecturer_referral_mapping,\n",
    "    'static_columns_preserved': ['course', 'academic_status', 'failed_subjects'],\n",
    "    'validation_passed': validation_result_referrals,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "log_path_v2 = '../data/cleaned_data/lecturer_referral_cleaning_log.json'\n",
    "with open(log_path_v2, 'w') as f:\n",
    "    json.dump(cleaning_log_v2, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Cleaning log saved to: {log_path_v2}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSUMMARY STATISTICS:\")\n",
    "print(\"-\"*25)\n",
    "print(f\"Total students: {len(df_with_referrals)}\")\n",
    "print(f\"Students with identified issues: {df_with_referrals['identified_issues'].notna().sum()}\")\n",
    "print(f\"Students without identified issues: {df_with_referrals['identified_issues'].isna().sum()}\")\n",
    "\n",
    "referral_cols = ['lecturer_referral_1', 'lecturer_referral_2', 'lecturer_referral_3']\n",
    "for col in referral_cols:\n",
    "    referral_count = df_with_referrals[col].notna().sum()\n",
    "    percentage = referral_count / len(df_with_referrals) * 100\n",
    "    print(f\"{col}: {referral_count} students ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ LECTURER REFERRAL CLEANING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"Key Results:\")\n",
    "print(\"â€¢ All students with identified issues have lecturer referrals\")\n",
    "print(\"â€¢ Less than 2% of students without issues have random referrals\")\n",
    "print(\"â€¢ Each lecturer referral column operates independently\")\n",
    "print(\"â€¢ All referral types follow the mapping rules\")\n",
    "print(\"â€¢ Data saved as student_data_v2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
