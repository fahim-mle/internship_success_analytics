{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Feature Engineering Phase 2: Correlation Analysis & Numeric Weights\n",
    "\n",
    "This notebook focuses on Phase 2 of feature engineering:\n",
    "1. Correlation analysis with the outcome variable 'risk'\n",
    "2. Creating JSON mappings for categorical variables\n",
    "3. Assigning numeric weights based on correlations\n",
    "4. Sentiment analysis and NLP processing for comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob not available. Will use basic sentiment scoring.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import chi2_contingency, pearsonr\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For sentiment analysis and NLP\n",
    "try:\n",
    "    from textblob import TextBlob\n",
    "    TEXTBLOB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"TextBlob not available. Will use basic sentiment scoring.\")\n",
    "    TEXTBLOB_AVAILABLE = False\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (282, 41)\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 282 entries, 0 to 281\n",
      "Data columns (total 41 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   student_id                    282 non-null    int64  \n",
      " 1   country                       282 non-null    object \n",
      " 2   course                        282 non-null    object \n",
      " 3   student_cohort                282 non-null    object \n",
      " 4   academic_status               282 non-null    object \n",
      " 5   failed_subjects               282 non-null    int64  \n",
      " 6   study_skills(attended)        282 non-null    object \n",
      " 7   referral                      282 non-null    object \n",
      " 8   pp_meeting                    282 non-null    object \n",
      " 9   self_assessment               109 non-null    object \n",
      " 10  readiness_assessment_results  282 non-null    object \n",
      " 11  follow_up                     282 non-null    object \n",
      " 12  follow_up_type                282 non-null    object \n",
      " 13  subject_1                     282 non-null    object \n",
      " 14  subject_1_assess_1            282 non-null    float64\n",
      " 15  subject_1_assess_2            282 non-null    float64\n",
      " 16  subject_1_assess_3            282 non-null    float64\n",
      " 17  subject_1_assess_4            282 non-null    float64\n",
      " 18  attendance_1                  282 non-null    float64\n",
      " 19  learn_jcu_issues_1            282 non-null    object \n",
      " 20  lecturer_referral_1           282 non-null    object \n",
      " 21  subject_2                     282 non-null    object \n",
      " 22  subject_2_assess_1            282 non-null    float64\n",
      " 23  subject_2_assess_2            282 non-null    float64\n",
      " 24  subject_2_assess_3            282 non-null    float64\n",
      " 25  subject_2_assess_4            282 non-null    float64\n",
      " 26  attendance_2                  282 non-null    float64\n",
      " 27  learn_jcu_issues_2            282 non-null    object \n",
      " 28  lecturer_referral_2           282 non-null    object \n",
      " 29  subject_3                     282 non-null    object \n",
      " 30  subject_3_assess_1            282 non-null    float64\n",
      " 31  subject_3_assess_2            282 non-null    float64\n",
      " 32  subject_3_assess_3            282 non-null    float64\n",
      " 33  subject_3_assess_4            282 non-null    float64\n",
      " 34  attendance_3                  282 non-null    float64\n",
      " 35  learn_jcu_issues_3            282 non-null    object \n",
      " 36  lecturer_referral_3           282 non-null    object \n",
      " 37  comments                      131 non-null    object \n",
      " 38  identified_issues             282 non-null    object \n",
      " 39  course_group                  282 non-null    object \n",
      " 40  risk                          282 non-null    object \n",
      "dtypes: float64(15), int64(2), object(24)\n",
      "memory usage: 90.5+ KB\n",
      "\n",
      "Risk distribution:\n",
      "risk\n",
      "medium    187\n",
      "high       95\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the engineered dataset from Phase 1\n",
    "df = pd.read_csv('../data/refined_data_for_model/engineered_student_data.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "df.info()\n",
    "print(f\"\\nRisk distribution:\")\n",
    "print(df['risk'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Correlation Analysis with Outcome Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Data for Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk encoding:\n",
      "  high: 0\n",
      "  medium: 1\n",
      "\n",
      "Numeric features (16): ['failed_subjects', 'subject_1_assess_1', 'subject_1_assess_2', 'subject_1_assess_3', 'subject_1_assess_4', 'attendance_1', 'subject_2_assess_1', 'subject_2_assess_2', 'subject_2_assess_3', 'subject_2_assess_4', 'attendance_2', 'subject_3_assess_1', 'subject_3_assess_2', 'subject_3_assess_3', 'subject_3_assess_4', 'attendance_3']\n",
      "\n",
      "Categorical features (23): ['country', 'course', 'student_cohort', 'academic_status', 'study_skills(attended)', 'referral', 'pp_meeting', 'self_assessment', 'readiness_assessment_results', 'follow_up', 'follow_up_type', 'subject_1', 'learn_jcu_issues_1', 'lecturer_referral_1', 'subject_2', 'learn_jcu_issues_2', 'lecturer_referral_2', 'subject_3', 'learn_jcu_issues_3', 'lecturer_referral_3', 'comments', 'identified_issues', 'course_group']\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for analysis\n",
    "df_analysis = df.copy()\n",
    "\n",
    "# Encode the target variable for correlation analysis\n",
    "risk_encoder = LabelEncoder()\n",
    "df_analysis['risk_encoded'] = risk_encoder.fit_transform(df_analysis['risk'])\n",
    "\n",
    "print(\"Risk encoding:\")\n",
    "for i, risk_level in enumerate(risk_encoder.classes_):\n",
    "    print(f\"  {risk_level}: {i}\")\n",
    "\n",
    "# Separate features by type\n",
    "numeric_features = df_analysis.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = df_analysis.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target and ID columns from feature lists\n",
    "numeric_features = [col for col in numeric_features if col not in ['student_id', 'risk_encoded']]\n",
    "categorical_features = [col for col in categorical_features if col not in ['student_id', 'risk']]\n",
    "\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Step 2: Numeric Features Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERIC FEATURES CORRELATION WITH RISK:\n",
      "==================================================\n",
      "failed_subjects           | Corr: -0.670 | P-value:  0.000\n",
      "subject_1_assess_1        | Corr:  0.431 | P-value:  0.000\n",
      "subject_1_assess_2        | Corr:  0.246 | P-value:  0.000\n",
      "subject_1_assess_3        | Corr:  0.296 | P-value:  0.000\n",
      "subject_1_assess_4        | Corr:  0.352 | P-value:  0.000\n",
      "attendance_1              | Corr:  0.399 | P-value:  0.000\n",
      "subject_2_assess_1        | Corr:  0.346 | P-value:  0.000\n",
      "subject_2_assess_2        | Corr:  0.386 | P-value:  0.000\n",
      "subject_2_assess_3        | Corr:  0.340 | P-value:  0.000\n",
      "subject_2_assess_4        | Corr:  0.410 | P-value:  0.000\n",
      "attendance_2              | Corr:  0.428 | P-value:  0.000\n",
      "subject_3_assess_1        | Corr:  0.336 | P-value:  0.000\n",
      "subject_3_assess_2        | Corr:  0.303 | P-value:  0.000\n",
      "subject_3_assess_3        | Corr:  0.342 | P-value:  0.000\n",
      "subject_3_assess_4        | Corr:  0.344 | P-value:  0.000\n",
      "attendance_3              | Corr:  0.428 | P-value:  0.000\n",
      "\n",
      "TOP NUMERIC CORRELATIONS:\n",
      "failed_subjects           | -0.670\n",
      "subject_1_assess_1        |  0.431\n",
      "attendance_2              |  0.428\n",
      "attendance_3              |  0.428\n",
      "subject_2_assess_4        |  0.410\n",
      "attendance_1              |  0.399\n",
      "subject_2_assess_2        |  0.386\n",
      "subject_1_assess_4        |  0.352\n",
      "subject_2_assess_1        |  0.346\n",
      "subject_3_assess_4        |  0.344\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlations for numeric features\n",
    "numeric_correlations = {}\n",
    "print(\"NUMERIC FEATURES CORRELATION WITH RISK:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for feature in numeric_features:\n",
    "    # Remove any NaN values for correlation calculation\n",
    "    valid_data = df_analysis[[feature, 'risk_encoded']].dropna()\n",
    "\n",
    "    if len(valid_data) > 1:\n",
    "        correlation, p_value = pearsonr(valid_data[feature], valid_data['risk_encoded'])\n",
    "        numeric_correlations[feature] = {\n",
    "            'correlation': correlation,\n",
    "            'p_value': p_value,\n",
    "            'abs_correlation': abs(correlation)\n",
    "        }\n",
    "        print(f\"{feature:25} | Corr: {correlation:6.3f} | P-value: {p_value:6.3f}\")\n",
    "    else:\n",
    "        numeric_correlations[feature] = {\n",
    "            'correlation': 0,\n",
    "            'p_value': 1.0,\n",
    "            'abs_correlation': 0\n",
    "        }\n",
    "        print(f\"{feature:25} | No valid data for correlation\")\n",
    "\n",
    "# Sort by absolute correlation\n",
    "sorted_numeric = sorted(numeric_correlations.items(),\n",
    "                       key=lambda x: x[1]['abs_correlation'], reverse=True)\n",
    "\n",
    "print(f\"\\nTOP NUMERIC CORRELATIONS:\")\n",
    "for feature, stats in sorted_numeric[:10]:\n",
    "    print(f\"{feature:25} | {stats['correlation']:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Step 3: Categorical Features Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORICAL FEATURES ASSOCIATION WITH RISK:\n",
      "=======================================================\n",
      "country                   | Chi2:    26.74 | P-val:  0.685 | Cramér's V: 0.308\n",
      "course                    | Chi2:    11.27 | P-val:  0.588 | Cramér's V: 0.200\n",
      "student_cohort            | Chi2:    89.20 | P-val:  0.000 | Cramér's V: 0.562\n",
      "academic_status           | Chi2:   184.76 | P-val:  0.000 | Cramér's V: 0.809\n",
      "study_skills(attended)    | Chi2:     5.57 | P-val:  0.351 | Cramér's V: 0.140\n",
      "referral                  | Chi2:     2.75 | P-val:  0.600 | Cramér's V: 0.099\n",
      "pp_meeting                | Chi2:     4.38 | P-val:  0.224 | Cramér's V: 0.125\n",
      "self_assessment           | Chi2:     0.00 | P-val:  1.000 | Cramér's V: 0.000\n",
      "readiness_assessment_results | Chi2:     0.00 | P-val:  1.000 | Cramér's V: nan\n",
      "follow_up                 | Chi2:     0.72 | P-val:  0.395 | Cramér's V: 0.051\n",
      "follow_up_type            | Chi2:     1.94 | P-val:  0.586 | Cramér's V: 0.083\n",
      "subject_1                 | Chi2:     9.22 | P-val:  0.512 | Cramér's V: 0.181\n",
      "learn_jcu_issues_1        | Chi2:     0.00 | P-val:  1.000 | Cramér's V: 0.000\n",
      "lecturer_referral_1       | Chi2:     2.13 | P-val:  0.345 | Cramér's V: 0.087\n",
      "subject_2                 | Chi2:     7.77 | P-val:  0.734 | Cramér's V: 0.166\n",
      "learn_jcu_issues_2        | Chi2:     0.20 | P-val:  0.653 | Cramér's V: 0.027\n",
      "lecturer_referral_2       | Chi2:     2.46 | P-val:  0.292 | Cramér's V: 0.093\n",
      "subject_3                 | Chi2:     7.78 | P-val:  0.733 | Cramér's V: 0.166\n",
      "learn_jcu_issues_3        | Chi2:     6.87 | P-val:  0.009 | Cramér's V: 0.156\n",
      "lecturer_referral_3       | Chi2:     0.08 | P-val:  0.961 | Cramér's V: 0.017\n",
      "comments                  | Chi2:    58.59 | P-val:  0.000 | Cramér's V: 0.669\n",
      "identified_issues         | Chi2:   111.79 | P-val:  0.000 | Cramér's V: 0.630\n",
      "course_group              | Chi2:     4.45 | P-val:  0.035 | Cramér's V: 0.126\n",
      "\n",
      "TOP CATEGORICAL ASSOCIATIONS:\n",
      "academic_status           | Cramér's V:  0.809\n",
      "student_cohort            | Cramér's V:  0.562\n",
      "readiness_assessment_results | Cramér's V:    nan\n",
      "comments                  | Cramér's V:  0.669\n",
      "identified_issues         | Cramér's V:  0.630\n",
      "country                   | Cramér's V:  0.308\n",
      "course                    | Cramér's V:  0.200\n",
      "subject_1                 | Cramér's V:  0.181\n",
      "subject_3                 | Cramér's V:  0.166\n",
      "subject_2                 | Cramér's V:  0.166\n"
     ]
    }
   ],
   "source": [
    "# Calculate chi-square test for categorical features\n",
    "categorical_associations = {}\n",
    "print(\"CATEGORICAL FEATURES ASSOCIATION WITH RISK:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "for feature in categorical_features:\n",
    "    try:\n",
    "        # Create contingency table\n",
    "        contingency_table = pd.crosstab(df_analysis[feature], df_analysis['risk'])\n",
    "\n",
    "        # Perform chi-square test\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "        # Calculate Cramér's V (effect size)\n",
    "        n = contingency_table.sum().sum()\n",
    "        cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
    "\n",
    "        categorical_associations[feature] = {\n",
    "            'chi2': chi2,\n",
    "            'p_value': p_value,\n",
    "            'cramers_v': cramers_v,\n",
    "            'unique_values': df_analysis[feature].nunique()\n",
    "        }\n",
    "\n",
    "        print(f\"{feature:25} | Chi2: {chi2:8.2f} | P-val: {p_value:6.3f} | Cramér's V: {cramers_v:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        categorical_associations[feature] = {\n",
    "            'chi2': 0,\n",
    "            'p_value': 1.0,\n",
    "            'cramers_v': 0,\n",
    "            'unique_values': df_analysis[feature].nunique()\n",
    "        }\n",
    "        print(f\"{feature:25} | Error: {str(e)}\")\n",
    "\n",
    "# Sort by Cramér's V\n",
    "sorted_categorical = sorted(categorical_associations.items(),\n",
    "                          key=lambda x: x[1]['cramers_v'], reverse=True)\n",
    "\n",
    "print(f\"\\nTOP CATEGORICAL ASSOCIATIONS:\")\n",
    "for feature, stats in sorted_categorical[:10]:\n",
    "    print(f\"{feature:25} | Cramér's V: {stats['cramers_v']:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. Create JSON Mapping for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING CATEGORICAL VARIABLE MAPPINGS:\n",
      "==================================================\n",
      "\n",
      "Analyzing country:\n",
      "  australia: Risk Score=44.4, High=33.3%, Medium=66.7%\n",
      "  bangladesh: Risk Score=43.8, High=31.2%, Medium=68.8%\n",
      "  bhutan: Risk Score=43.5, High=30.6%, Medium=69.4%\n",
      "  chile: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  colombia: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  ghana: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  india: Risk Score=42.2, High=26.5%, Medium=73.5%\n",
      "  jordan: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  kenya: Risk Score=46.5, High=39.5%, Medium=60.5%\n",
      "  malaysia: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  nepal: Risk Score=45.6, High=36.7%, Medium=63.3%\n",
      "  papua new guinea: Risk Score=42.6, High=27.8%, Medium=72.2%\n",
      "  philippines: Risk Score=44.4, High=33.3%, Medium=66.7%\n",
      "  vietnam: Risk Score=40.7, High=22.2%, Medium=77.8%\n",
      "  zimbabwe: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  nigeria: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  china: Risk Score=47.2, High=41.7%, Medium=58.3%\n",
      "  uganda: Risk Score=57.1, High=71.4%, Medium=28.6%\n",
      "  fiji: Risk Score=40.0, High=20.0%, Medium=80.0%\n",
      "  hong kong: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  indonesia: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  laos: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  repubic of korea (south): Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  russia: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  pakistan: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  turkey: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  mongolia: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  myanmar: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  rwanda: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  sri lanka: Risk Score=55.6, High=66.7%, Medium=33.3%\n",
      "  taiwan: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "  thailand: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "\n",
      "Analyzing course:\n",
      "  mba: Risk Score=42.1, High=26.3%, Medium=73.7%\n",
      "  med-mba: Risk Score=44.1, High=32.3%, Medium=67.7%\n",
      "  minftech: Risk Score=46.8, High=40.5%, Medium=59.5%\n",
      "  bbus: Risk Score=43.1, High=29.4%, Medium=70.6%\n",
      "  mengmgmt: Risk Score=44.0, High=32.1%, Medium=67.9%\n",
      "  binftech: Risk Score=47.4, High=42.3%, Medium=57.7%\n",
      "  mpa: Risk Score=44.4, High=33.3%, Medium=66.7%\n",
      "  mintltourismandhospmgt: Risk Score=39.2, High=17.6%, Medium=82.4%\n",
      "  bthe: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  mpa-mba: Risk Score=42.9, High=28.6%, Medium=71.4%\n",
      "  bcom: Risk Score=41.7, High=25.0%, Medium=75.0%\n",
      "  mithm-mba: Risk Score=40.7, High=22.2%, Medium=77.8%\n",
      "  mdatasc(prof): Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  minftech-mba: Risk Score=58.3, High=75.0%, Medium=25.0%\n",
      "\n",
      "Analyzing student_cohort:\n",
      "  continuing: Risk Score=56.4, High=69.2%, Medium=30.8%\n",
      "  new: Risk Score=38.2, High=14.7%, Medium=85.3%\n",
      "  return to study: Risk Score=60.2, High=80.6%, Medium=19.4%\n",
      "  loa: Risk Score=58.7, High=76.2%, Medium=23.8%\n",
      "  first year: Risk Score=41.7, High=25.0%, Medium=75.0%\n",
      "  transferred: Risk Score=41.7, High=25.0%, Medium=75.0%\n",
      "  excluded: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  sri to jcub: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "\n",
      "Analyzing academic_status:\n",
      "  conditional: Risk Score=65.2, High=95.5%, Medium=4.5%\n",
      "  satisfactory: Risk Score=36.7, High=10.2%, Medium=89.8%\n",
      "  academic caution: Risk Score=65.3, High=96.0%, Medium=4.0%\n",
      "  excluded: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "\n",
      "Analyzing study_skills(attended):\n",
      "  essential skills: Risk Score=46.8, High=40.4%, Medium=59.6%\n",
      "  writing: Risk Score=43.2, High=29.5%, Medium=70.5%\n",
      "  essential skills and reading: Risk Score=43.6, High=30.8%, Medium=69.2%\n",
      "  4r essential skills: Risk Score=48.8, High=46.3%, Medium=53.7%\n",
      "  referencing: Risk Score=43.1, High=29.3%, Medium=70.7%\n",
      "  studiocity: Risk Score=42.8, High=28.3%, Medium=71.7%\n",
      "\n",
      "Analyzing referral:\n",
      "  student counsellor: Risk Score=46.7, High=40.0%, Medium=60.0%\n",
      "  enrollment: Risk Score=44.0, High=32.1%, Medium=67.9%\n",
      "  lecturer: Risk Score=43.7, High=31.0%, Medium=69.0%\n",
      "  student advocate: Risk Score=42.2, High=26.5%, Medium=73.5%\n",
      "  other: Risk Score=45.9, High=37.7%, Medium=62.3%\n",
      "\n",
      "Analyzing pp_meeting:\n",
      "  booked: Risk Score=44.0, High=32.1%, Medium=67.9%\n",
      "  attended: Risk Score=45.2, High=35.6%, Medium=64.4%\n",
      "  not relevant: Risk Score=47.0, High=41.1%, Medium=58.9%\n",
      "  rescheduled: Risk Score=41.4, High=24.1%, Medium=75.9%\n",
      "\n",
      "Analyzing self_assessment:\n",
      "  yes: Risk Score=38.0, High=14.0%, Medium=86.0%\n",
      "  no: Risk Score=38.5, High=15.4%, Medium=84.6%\n",
      "\n",
      "Analyzing readiness_assessment_results:\n",
      "  l/g:9/10 n:5/10 r:8/10: Risk Score=44.6, High=33.7%, Medium=66.3%\n",
      "\n",
      "Analyzing follow_up:\n",
      "  yes: Risk Score=43.7, High=31.1%, Medium=68.9%\n",
      "  no: Risk Score=45.5, High=36.6%, Medium=63.4%\n",
      "\n",
      "Analyzing follow_up_type:\n",
      "  no reply: Risk Score=45.2, High=35.7%, Medium=64.3%\n",
      "  phone: Risk Score=46.3, High=38.9%, Medium=61.1%\n",
      "  f2f: Risk Score=43.0, High=28.9%, Medium=71.1%\n",
      "  email: Risk Score=43.8, High=31.2%, Medium=68.8%\n",
      "\n",
      "Analyzing subject_1:\n",
      "  lb5113: Risk Score=42.1, High=26.3%, Medium=73.7%\n",
      "  ed5097: Risk Score=44.1, High=32.3%, Medium=67.7%\n",
      "  cp5046: Risk Score=47.8, High=43.5%, Medium=56.5%\n",
      "  bu1002: Risk Score=43.1, High=29.4%, Medium=70.6%\n",
      "  eg5200: Risk Score=44.0, High=32.1%, Medium=67.9%\n",
      "  cp1401: Risk Score=47.4, High=42.3%, Medium=57.7%\n",
      "  co5117: Risk Score=44.0, High=32.0%, Medium=68.0%\n",
      "  to5101: Risk Score=39.7, High=19.2%, Medium=80.8%\n",
      "  to1008: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  bu1112: Risk Score=41.7, High=25.0%, Medium=75.0%\n",
      "  ma5831: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "\n",
      "Analyzing learn_jcu_issues_1:\n",
      "  access: Risk Score=44.5, High=33.5%, Medium=66.5%\n",
      "  no access: Risk Score=44.7, High=34.2%, Medium=65.8%\n",
      "\n",
      "Analyzing lecturer_referral_1:\n",
      "  concern for welfare: Risk Score=44.8, High=34.4%, Medium=65.6%\n",
      "  attendance: Risk Score=46.2, High=38.5%, Medium=61.5%\n",
      "  non submission: Risk Score=42.8, High=28.4%, Medium=71.6%\n",
      "\n",
      "Analyzing subject_2:\n",
      "  lb5202: Risk Score=42.1, High=26.3%, Medium=73.7%\n",
      "  ed5880: Risk Score=44.1, High=32.3%, Medium=67.7%\n",
      "  cp5047: Risk Score=46.8, High=40.5%, Medium=59.5%\n",
      "  bu1003: Risk Score=43.1, High=29.4%, Medium=70.6%\n",
      "  eg5220: Risk Score=44.0, High=32.1%, Medium=67.9%\n",
      "  cp1402: Risk Score=47.4, High=42.3%, Medium=57.7%\n",
      "  co5103: Risk Score=44.0, High=32.0%, Medium=68.0%\n",
      "  to5103: Risk Score=39.2, High=17.6%, Medium=82.4%\n",
      "  to2117: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  bx2011: Risk Score=41.7, High=25.0%, Medium=75.0%\n",
      "  lb5113: Risk Score=46.2, High=38.5%, Medium=61.5%\n",
      "  ma5840: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "\n",
      "Analyzing learn_jcu_issues_2:\n",
      "  access: Risk Score=44.2, High=32.7%, Medium=67.3%\n",
      "  no access: Risk Score=45.5, High=36.5%, Medium=63.5%\n",
      "\n",
      "Analyzing lecturer_referral_2:\n",
      "  attendance: Risk Score=46.7, High=40.0%, Medium=60.0%\n",
      "  concern for welfare: Risk Score=44.2, High=32.7%, Medium=67.3%\n",
      "  non submission: Risk Score=43.0, High=29.0%, Medium=71.0%\n",
      "\n",
      "Analyzing subject_3:\n",
      "  lb5205: Risk Score=42.1, High=26.3%, Medium=73.7%\n",
      "  lb5113: Risk Score=43.9, High=31.6%, Medium=68.4%\n",
      "  cp5503: Risk Score=46.8, High=40.5%, Medium=59.5%\n",
      "  bu1007: Risk Score=43.1, High=29.4%, Medium=70.6%\n",
      "  eg5310: Risk Score=44.0, High=32.1%, Medium=67.9%\n",
      "  cp1404: Risk Score=47.4, High=42.3%, Medium=57.7%\n",
      "  co5109: Risk Score=44.4, High=33.3%, Medium=66.7%\n",
      "  to5104: Risk Score=39.2, High=17.6%, Medium=82.4%\n",
      "  to3052: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "  bx2014: Risk Score=41.7, High=25.0%, Medium=75.0%\n",
      "  lb5202: Risk Score=46.2, High=38.5%, Medium=61.5%\n",
      "  ma5851: Risk Score=50.0, High=50.0%, Medium=50.0%\n",
      "\n",
      "Analyzing learn_jcu_issues_3:\n",
      "  access: Risk Score=43.2, High=29.5%, Medium=70.5%\n",
      "  no access: Risk Score=49.5, High=48.4%, Medium=51.6%\n",
      "\n",
      "Analyzing lecturer_referral_3:\n",
      "  non submission: Risk Score=44.6, High=33.9%, Medium=66.1%\n",
      "  attendance: Risk Score=44.2, High=32.6%, Medium=67.4%\n",
      "  concern for welfare: Risk Score=44.9, High=34.6%, Medium=65.4%\n",
      "\n",
      "Analyzing comments:\n",
      "  week 6. student reported working long hours. referred to careers support for managing work–study balance.: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  week 2. student did not attend orientation. contacted via email with essential course info and moodle access guide. no response yet: Risk Score=47.5, High=42.4%, Medium=57.6%\n",
      "  week 6. student submitted assessment late. extension not requested in advance. advised to submit future requests on time and referred to academic skills team.: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  week 4. student submitted first assessment late. offered academic skills support and advised on extension procedures.: Risk Score=41.3, High=23.8%, Medium=76.2%\n",
      "  week 7. student disclosed high stress levels and lack of sleep. referred to wellbeing team and reminded of available mental health support.: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  week 3. student enrolled late. missing foundational content from weeks 1–2. provided links to recorded lectures and encouraged to attend tutorials for extra support.: Risk Score=63.0, High=88.9%, Medium=11.1%\n",
      "  week 5. low engagement in tutorials. follow-up email sent with participation expectations and links to recorded sessions.: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  week 3. first contact made. student reported internet access issues at home. it support referral provided.: Risk Score=62.5, High=87.5%, Medium=12.5%\n",
      "  week 5. student absent from multiple classes. email sent to check in; student replied citing family issues. offered flexibility and reminded of support services.: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  week 7. missed second assessment. student contacted and reported feeling overwhelmed. referred to academic support and encouraged to speak with counsellor.: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "\n",
      "Analyzing identified_issues:\n",
      "  late enrollment: Risk Score=44.3, High=32.8%, Medium=67.2%\n",
      "  sickness: Risk Score=62.2, High=86.7%, Medium=13.3%\n",
      "  death in family: Risk Score=63.0, High=88.9%, Medium=11.1%\n",
      "  no issue reported: Risk Score=37.5, High=12.5%, Medium=87.5%\n",
      "  mental health: Risk Score=59.3, High=77.8%, Medium=22.2%\n",
      "  poor time management: Risk Score=66.7, High=100.0%, Medium=0.0%\n",
      "  concern for welfare: Risk Score=33.3, High=0.0%, Medium=100.0%\n",
      "\n",
      "Analyzing course_group:\n",
      "  non-it: Risk Score=43.2, High=29.7%, Medium=70.3%\n",
      "  it: Risk Score=47.9, High=43.8%, Medium=56.2%\n",
      "\n",
      "Completed mappings for 23 categorical features.\n"
     ]
    }
   ],
   "source": [
    "# Create detailed mappings for categorical variables based on their association with risk\n",
    "categorical_mappings = {}\n",
    "\n",
    "print(\"CREATING CATEGORICAL VARIABLE MAPPINGS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(f\"\\nAnalyzing {feature}:\")\n",
    "\n",
    "    # Get value counts by risk level\n",
    "    risk_breakdown = pd.crosstab(df_analysis[feature], df_analysis['risk'], normalize='index') * 100\n",
    "\n",
    "    # Calculate risk scores for each category\n",
    "    category_scores = {}\n",
    "\n",
    "    for category in df_analysis[feature].unique():\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "\n",
    "        category_data = df_analysis[df_analysis[feature] == category]\n",
    "\n",
    "        if len(category_data) > 0:\n",
    "            # Calculate percentage of high risk students in this category\n",
    "            high_risk_pct = (category_data['risk'] == 'high').mean() * 100\n",
    "            medium_risk_pct = (category_data['risk'] == 'medium').mean() * 100\n",
    "\n",
    "            # Create composite risk score (weighted towards high risk)\n",
    "            risk_score = (high_risk_pct * 2 + medium_risk_pct) / 3\n",
    "\n",
    "            category_scores[str(category)] = {\n",
    "                'risk_score': round(risk_score, 2),\n",
    "                'high_risk_pct': round(high_risk_pct, 1),\n",
    "                'medium_risk_pct': round(medium_risk_pct, 1),\n",
    "                'count': len(category_data)\n",
    "            }\n",
    "\n",
    "            print(f\"  {category}: Risk Score={risk_score:.1f}, High={high_risk_pct:.1f}%, Medium={medium_risk_pct:.1f}%\")\n",
    "\n",
    "    # Sort categories by risk score\n",
    "    sorted_categories = sorted(category_scores.items(), key=lambda x: x[1]['risk_score'], reverse=True)\n",
    "\n",
    "    # Assign numeric weights based on ranking\n",
    "    weights = {}\n",
    "    for i, (category, scores) in enumerate(sorted_categories):\n",
    "        # Higher risk categories get higher weights\n",
    "        weight = len(sorted_categories) - i\n",
    "        weights[category] = weight\n",
    "\n",
    "    categorical_mappings[feature] = {\n",
    "        'association_strength': categorical_associations[feature]['cramers_v'],\n",
    "        'category_details': category_scores,\n",
    "        'numeric_weights': weights,\n",
    "        'unique_count': len(category_scores)\n",
    "    }\n",
    "\n",
    "print(f\"\\nCompleted mappings for {len(categorical_mappings)} categorical features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Save JSON Mapping File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mappings saved to: ../data/refined_data_for_model/feature_mappings.json\n",
      "\n",
      "Mapping summary:\n",
      "  - Numeric features analyzed: 16\n",
      "  - Categorical features analyzed: 23\n",
      "  - Total features mapped: 39\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive mapping structure\n",
    "feature_mappings = {\n",
    "    'metadata': {\n",
    "        'created_date': pd.Timestamp.now().isoformat(),\n",
    "        'dataset_shape': df.shape,\n",
    "        'risk_levels': list(df['risk'].unique()),\n",
    "        'risk_distribution': df['risk'].value_counts().to_dict()\n",
    "    },\n",
    "    'numeric_features': {\n",
    "        'correlations': {k: v for k, v in numeric_correlations.items()},\n",
    "        'top_features': [item[0] for item in sorted_numeric[:10]]\n",
    "    },\n",
    "    'categorical_features': categorical_mappings\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = '../data/refined_data_for_model/feature_mappings.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(feature_mappings, f, indent=2)\n",
    "\n",
    "print(f\"Feature mappings saved to: {output_path}\")\n",
    "print(f\"\\nMapping summary:\")\n",
    "print(f\"  - Numeric features analyzed: {len(numeric_correlations)}\")\n",
    "print(f\"  - Categorical features analyzed: {len(categorical_mappings)}\")\n",
    "print(f\"  - Total features mapped: {len(numeric_correlations) + len(categorical_mappings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 4. Apply Numeric Weights to Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING NUMERIC WEIGHTS TO CATEGORICAL VARIABLES:\n",
      "=======================================================\n",
      "country                   -> country_weighted                    | Unique weights: 32\n",
      "  Weight distribution: {1: np.int64(1), 2: np.int64(1), 3: np.int64(1), 4: np.int64(1), 5: np.int64(1), 6: np.int64(3), 7: np.int64(1), 8: np.int64(1), 9: np.int64(1), 10: np.int64(1), 11: np.int64(5), 12: np.int64(9), 13: np.int64(49), 14: np.int64(18), 15: np.int64(62), 16: np.int64(16), 17: np.int64(3), 18: np.int64(3), 19: np.int64(30), 20: np.int64(38), 21: np.int64(12), 22: np.int64(2), 23: np.int64(2), 24: np.int64(4), 25: np.int64(2), 26: np.int64(3), 27: np.int64(7), 28: np.int64(1), 29: np.int64(1), 30: np.int64(1), 31: np.int64(1), 32: np.int64(1)}\n",
      "course                    -> course_weighted                     | Unique weights: 14\n",
      "  Weight distribution: {1: np.int64(17), 2: np.int64(9), 3: np.int64(8), 4: np.int64(38), 5: np.int64(7), 6: np.int64(34), 7: np.int64(28), 8: np.int64(31), 9: np.int64(18), 10: np.int64(42), 11: np.int64(26), 12: np.int64(8), 13: np.int64(12), 14: np.int64(4)}\n",
      "student_cohort            -> student_cohort_weighted             | Unique weights: 8\n",
      "  Weight distribution: {1: np.int64(7), 2: np.int64(109), 3: np.int64(4), 4: np.int64(92), 5: np.int64(13), 6: np.int64(21), 7: np.int64(31), 8: np.int64(5)}\n",
      "academic_status           -> academic_status_weighted            | Unique weights: 4\n",
      "  Weight distribution: {1: np.int64(205), 2: np.int64(22), 3: np.int64(50), 4: np.int64(5)}\n",
      "study_skills(attended)    -> study_skills(attended)_weighted     | Unique weights: 6\n",
      "  Weight distribution: {1: np.int64(53), 2: np.int64(58), 3: np.int64(44), 4: np.int64(39), 5: np.int64(47), 6: np.int64(41)}\n",
      "referral                  -> referral_weighted                   | Unique weights: 5\n",
      "  Weight distribution: {1: np.int64(49), 2: np.int64(58), 3: np.int64(56), 4: np.int64(69), 5: np.int64(50)}\n",
      "pp_meeting                -> pp_meeting_weighted                 | Unique weights: 4\n",
      "  Weight distribution: {1: np.int64(58), 2: np.int64(78), 3: np.int64(73), 4: np.int64(73)}\n",
      "self_assessment           -> self_assessment_weighted            | Unique weights: 2\n",
      "  Weight distribution: {1.0: np.int64(57), 1.5: np.int64(173), 2.0: np.int64(52)}\n",
      "readiness_assessment_results -> readiness_assessment_results_weighted | Unique weights: 1\n",
      "  Weight distribution: {1: np.int64(282)}\n",
      "follow_up                 -> follow_up_weighted                  | Unique weights: 2\n",
      "  Weight distribution: {1: np.int64(151), 2: np.int64(131)}\n",
      "follow_up_type            -> follow_up_type_weighted             | Unique weights: 4\n",
      "  Weight distribution: {1: np.int64(76), 2: np.int64(64), 3: np.int64(70), 4: np.int64(72)}\n",
      "subject_1                 -> subject_1_weighted                  | Unique weights: 11\n",
      "  Weight distribution: {1: np.int64(26), 2: np.int64(8), 3: np.int64(38), 4: np.int64(34), 5: np.int64(25), 6: np.int64(28), 7: np.int64(31), 8: np.int64(26), 9: np.int64(46), 10: np.int64(8), 11: np.int64(12)}\n",
      "learn_jcu_issues_1        -> learn_jcu_issues_1_weighted         | Unique weights: 2\n",
      "  Weight distribution: {1: np.int64(209), 2: np.int64(73)}\n",
      "lecturer_referral_1       -> lecturer_referral_1_weighted        | Unique weights: 3\n",
      "  Weight distribution: {1: np.int64(95), 2: np.int64(96), 3: np.int64(91)}\n",
      "subject_2                 -> subject_2_weighted                  | Unique weights: 12\n",
      "  Weight distribution: {1: np.int64(17), 2: np.int64(8), 3: np.int64(38), 4: np.int64(34), 5: np.int64(25), 6: np.int64(28), 7: np.int64(31), 8: np.int64(13), 9: np.int64(42), 10: np.int64(26), 11: np.int64(8), 12: np.int64(12)}\n",
      "learn_jcu_issues_2        -> learn_jcu_issues_2_weighted         | Unique weights: 2\n",
      "  Weight distribution: {1: np.int64(208), 2: np.int64(74)}\n",
      "lecturer_referral_2       -> lecturer_referral_2_weighted        | Unique weights: 3\n",
      "  Weight distribution: {1: np.int64(93), 2: np.int64(104), 3: np.int64(85)}\n",
      "subject_3                 -> subject_3_weighted                  | Unique weights: 12\n",
      "  Weight distribution: {1: np.int64(17), 2: np.int64(8), 3: np.int64(38), 4: np.int64(34), 5: np.int64(38), 6: np.int64(28), 7: np.int64(18), 8: np.int64(13), 9: np.int64(42), 10: np.int64(26), 11: np.int64(8), 12: np.int64(12)}\n",
      "learn_jcu_issues_3        -> learn_jcu_issues_3_weighted         | Unique weights: 2\n",
      "  Weight distribution: {1: np.int64(220), 2: np.int64(62)}\n",
      "lecturer_referral_3       -> lecturer_referral_3_weighted        | Unique weights: 3\n",
      "  Weight distribution: {1: np.int64(89), 2: np.int64(112), 3: np.int64(81)}\n",
      "comments                  -> comments_weighted                   | Unique weights: 10\n",
      "  Weight distribution: {1.0: np.int64(42), 2.0: np.int64(33), 3.0: np.int64(8), 4.0: np.int64(9), 5.0: np.int64(2), 5.5: np.int64(151), 6.0: np.int64(4), 7.0: np.int64(3), 8.0: np.int64(17), 9.0: np.int64(10), 10.0: np.int64(3)}\n",
      "identified_issues         -> identified_issues_weighted          | Unique weights: 7\n",
      "  Weight distribution: {1: np.int64(1), 2: np.int64(152), 3: np.int64(67), 4: np.int64(18), 5: np.int64(15), 6: np.int64(18), 7: np.int64(11)}\n",
      "course_group              -> course_group_weighted               | Unique weights: 2\n",
      "  Weight distribution: {1: np.int64(202), 2: np.int64(80)}\n",
      "\n",
      "Weighted dataset shape: (282, 64)\n",
      "New weighted columns added: 23\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe with numeric weights applied\n",
    "df_weighted = df.copy()\n",
    "\n",
    "print(\"APPLYING NUMERIC WEIGHTS TO CATEGORICAL VARIABLES:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in categorical_mappings:\n",
    "        weights = categorical_mappings[feature]['numeric_weights']\n",
    "\n",
    "        # Create new weighted column\n",
    "        weighted_col = f\"{feature}_weighted\"\n",
    "        df_weighted[weighted_col] = df_weighted[feature].astype(str).map(weights)\n",
    "\n",
    "        # Handle any unmapped values with median weight\n",
    "        median_weight = np.median(list(weights.values()))\n",
    "        df_weighted[weighted_col] = df_weighted[weighted_col].fillna(median_weight)\n",
    "\n",
    "        print(f\"{feature:25} -> {weighted_col:35} | Unique weights: {len(weights)}\")\n",
    "\n",
    "        # Show weight distribution\n",
    "        weight_dist = df_weighted[weighted_col].value_counts().sort_index()\n",
    "        print(f\"  Weight distribution: {dict(weight_dist)}\")\n",
    "\n",
    "print(f\"\\nWeighted dataset shape: {df_weighted.shape}\")\n",
    "print(f\"New weighted columns added: {len([col for col in df_weighted.columns if col.endswith('_weighted')])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis and NLP for Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Step 1: Identify Comment Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDENTIFYING COMMENT FIELDS:\n",
      "==============================\n",
      "country                   | Avg Length:   6.7 | Unique Ratio: 0.113\n",
      "course                    | Avg Length:   7.2 | Unique Ratio: 0.050\n",
      "student_cohort            | Avg Length:   7.3 | Unique Ratio: 0.028\n",
      "academic_status           | Avg Length:  12.6 | Unique Ratio: 0.014\n",
      "study_skills(attended)    | Avg Length:  14.5 | Unique Ratio: 0.021\n",
      "referral                  | Avg Length:  10.8 | Unique Ratio: 0.018\n",
      "pp_meeting                | Avg Length:   9.1 | Unique Ratio: 0.014\n",
      "self_assessment           | Avg Length:   2.8 | Unique Ratio: 0.007\n",
      "readiness_assessment_results | Avg Length:  22.0 | Unique Ratio: 0.004\n",
      "  -> Identified as COMMENT field\n",
      "follow_up                 | Avg Length:   2.5 | Unique Ratio: 0.007\n",
      "follow_up_type            | Avg Length:   5.2 | Unique Ratio: 0.014\n",
      "subject_1                 | Avg Length:   6.0 | Unique Ratio: 0.039\n",
      "learn_jcu_issues_1        | Avg Length:   6.8 | Unique Ratio: 0.007\n",
      "lecturer_referral_1       | Avg Length:  14.4 | Unique Ratio: 0.011\n",
      "subject_2                 | Avg Length:   6.0 | Unique Ratio: 0.043\n",
      "learn_jcu_issues_2        | Avg Length:   6.8 | Unique Ratio: 0.007\n",
      "lecturer_referral_2       | Avg Length:  14.6 | Unique Ratio: 0.011\n",
      "subject_3                 | Avg Length:   6.0 | Unique Ratio: 0.043\n",
      "learn_jcu_issues_3        | Avg Length:   6.7 | Unique Ratio: 0.007\n",
      "lecturer_referral_3       | Avg Length:  14.2 | Unique Ratio: 0.011\n",
      "comments                  | Avg Length:  62.4 | Unique Ratio: 0.035\n",
      "  -> Identified as COMMENT field\n",
      "identified_issues         | Avg Length:  15.8 | Unique Ratio: 0.025\n",
      "course_group              | Avg Length:   4.9 | Unique Ratio: 0.007\n",
      "\n",
      "Comment fields identified: ['readiness_assessment_results', 'comments']\n"
     ]
    }
   ],
   "source": [
    "# Identify potential comment/text fields\n",
    "comment_fields = []\n",
    "text_fields = df_weighted.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"IDENTIFYING COMMENT FIELDS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for field in text_fields:\n",
    "    if field not in ['student_id', 'risk'] and not field.endswith('_weighted'):\n",
    "        # Check if field contains longer text (potential comments)\n",
    "        avg_length = df_weighted[field].astype(str).str.len().mean()\n",
    "        unique_ratio = df_weighted[field].nunique() / len(df_weighted)\n",
    "\n",
    "        print(f\"{field:25} | Avg Length: {avg_length:5.1f} | Unique Ratio: {unique_ratio:.3f}\")\n",
    "\n",
    "        # Consider as comment field if average length > 20 chars or high uniqueness\n",
    "        if avg_length > 20 or unique_ratio > 0.5:\n",
    "            comment_fields.append(field)\n",
    "            print(f\"  -> Identified as COMMENT field\")\n",
    "\n",
    "print(f\"\\nComment fields identified: {comment_fields}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### Step 2: Sentiment Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis function defined.\n",
      "\n",
      "Testing sentiment analysis:\n",
      "'This student is performing excellently' -> positive (0.2)\n",
      "'Student is struggling with attendance issues' -> negative (-0.4)\n",
      "'Average performance, no major concerns' -> neutral (0)\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of text and return scores\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        return {\n",
    "            'sentiment_score': 0,\n",
    "            'sentiment_category': 'neutral',\n",
    "            'text_length': 0,\n",
    "            'word_count': 0\n",
    "        }\n",
    "\n",
    "    text_str = str(text).lower()\n",
    "\n",
    "    if TEXTBLOB_AVAILABLE:\n",
    "        # Use TextBlob for sentiment analysis\n",
    "        blob = TextBlob(text_str)\n",
    "        sentiment_score = blob.sentiment.polarity  # -1 to 1\n",
    "    else:\n",
    "        # Simple keyword-based sentiment scoring\n",
    "        positive_words = ['good', 'excellent', 'great', 'outstanding', 'positive', 'strong', 'effective']\n",
    "        negative_words = ['poor', 'bad', 'terrible', 'weak', 'negative', 'struggling', 'concerning', 'issue']\n",
    "\n",
    "        pos_count = sum(1 for word in positive_words if word in text_str)\n",
    "        neg_count = sum(1 for word in negative_words if word in text_str)\n",
    "\n",
    "        # Simple scoring\n",
    "        if pos_count > neg_count:\n",
    "            sentiment_score = min(0.5, pos_count * 0.2)\n",
    "        elif neg_count > pos_count:\n",
    "            sentiment_score = max(-0.5, -neg_count * 0.2)\n",
    "        else:\n",
    "            sentiment_score = 0\n",
    "\n",
    "    # Categorize sentiment\n",
    "    if sentiment_score > 0.1:\n",
    "        category = 'positive'\n",
    "    elif sentiment_score < -0.1:\n",
    "        category = 'negative'\n",
    "    else:\n",
    "        category = 'neutral'\n",
    "\n",
    "    return {\n",
    "        'sentiment_score': round(sentiment_score, 3),\n",
    "        'sentiment_category': category,\n",
    "        'text_length': len(text_str),\n",
    "        'word_count': len(text_str.split())\n",
    "    }\n",
    "\n",
    "print(\"Sentiment analysis function defined.\")\n",
    "print(\"\\nTesting sentiment analysis:\")\n",
    "test_texts = [\n",
    "    \"This student is performing excellently\",\n",
    "    \"Student is struggling with attendance issues\",\n",
    "    \"Average performance, no major concerns\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = analyze_sentiment(text)\n",
    "    print(f\"'{text}' -> {result['sentiment_category']} ({result['sentiment_score']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Step 3: Apply Sentiment Analysis to Comment Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING SENTIMENT ANALYSIS:\n",
      "===================================\n",
      "\n",
      "Processing readiness_assessment_results...\n",
      "  Sentiment distribution: {'neutral': np.int64(282)}\n",
      "  Sentiment vs Risk (% by sentiment):\n",
      "risk                                             high  medium\n",
      "readiness_assessment_results_sentiment_category              \n",
      "neutral                                          33.7    66.3\n",
      "\n",
      "Processing comments...\n",
      "  Sentiment distribution: {'neutral': np.int64(270), 'negative': np.int64(12)}\n",
      "  Sentiment vs Risk (% by sentiment):\n",
      "risk                         high  medium\n",
      "comments_sentiment_category              \n",
      "negative                     91.7     8.3\n",
      "neutral                      31.1    68.9\n",
      "\n",
      "Sentiment analysis completed for 2 comment fields.\n",
      "Added 8 new sentiment-related columns.\n"
     ]
    }
   ],
   "source": [
    "# Apply sentiment analysis to identified comment fields\n",
    "print(\"APPLYING SENTIMENT ANALYSIS:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "for field in comment_fields:\n",
    "    print(f\"\\nProcessing {field}...\")\n",
    "\n",
    "    # Apply sentiment analysis\n",
    "    sentiment_results = df_weighted[field].apply(analyze_sentiment)\n",
    "\n",
    "    # Extract sentiment components\n",
    "    df_weighted[f\"{field}_sentiment_score\"] = [r['sentiment_score'] for r in sentiment_results]\n",
    "    df_weighted[f\"{field}_sentiment_category\"] = [r['sentiment_category'] for r in sentiment_results]\n",
    "    df_weighted[f\"{field}_text_length\"] = [r['text_length'] for r in sentiment_results]\n",
    "    df_weighted[f\"{field}_word_count\"] = [r['word_count'] for r in sentiment_results]\n",
    "\n",
    "    # Show sentiment distribution\n",
    "    sentiment_dist = df_weighted[f\"{field}_sentiment_category\"].value_counts()\n",
    "    print(f\"  Sentiment distribution: {dict(sentiment_dist)}\")\n",
    "\n",
    "    # Analyze sentiment vs risk\n",
    "    sentiment_risk = pd.crosstab(df_weighted[f\"{field}_sentiment_category\"],\n",
    "                                df_weighted['risk'], normalize='index') * 100\n",
    "    print(f\"  Sentiment vs Risk (% by sentiment):\")\n",
    "    print(sentiment_risk.round(1))\n",
    "\n",
    "if comment_fields:\n",
    "    print(f\"\\nSentiment analysis completed for {len(comment_fields)} comment fields.\")\n",
    "    print(f\"Added {len(comment_fields) * 4} new sentiment-related columns.\")\n",
    "else:\n",
    "    print(\"\\nNo comment fields identified for sentiment analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 6. Final Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 2 FEATURE ENGINEERING COMPLETION SUMMARY\n",
      "============================================================\n",
      "\n",
      "✅ COMPLETED TASKS:\n",
      "   1. ✅ Loaded engineered_student_data.csv\n",
      "   2. ✅ Analyzed correlations for 16 numeric features\n",
      "   3. ✅ Analyzed associations for 23 categorical features\n",
      "   4. ✅ Created JSON mapping with numeric weights\n",
      "   5. ✅ Applied numeric weights to categorical variables\n",
      "   6. ✅ Performed sentiment analysis on 2 comment fields\n",
      "   7. ✅ Created comprehensive feature-engineered dataset\n",
      "\n",
      "📊 FINAL DATASET STATUS:\n",
      "   • Original features: 41\n",
      "   • Final features: 72\n",
      "   • New features added: 31\n",
      "   • Weighted categorical features: 23\n",
      "   • Sentiment features: 4\n",
      "\n",
      "📁 OUTPUT FILES:\n",
      "   • Feature mappings: ../data/refined_data_for_model/feature_mappings.json\n",
      "   • Engineered dataset: ../data/refined_data_for_model/fully_engineered_student_data.csv\n",
      "\n",
      "🚀 READY FOR PREDICTION MODEL:\n",
      "   • Dataset shape: (282, 72)\n",
      "   • Target variable: 'risk' (medium/high)\n",
      "   • Features ready for model training\n",
      "\n",
      "📋 FEATURE SUMMARY:\n",
      "   • Original features: 45\n",
      "   • Weighted categorical: 23\n",
      "   • Sentiment/NLP features: 8\n",
      "   • Total engineered features: 31\n"
     ]
    }
   ],
   "source": [
    "# Save the final engineered dataset\n",
    "output_path = '../data/refined_data_for_model/fully_engineered_student_data.csv'\n",
    "df_weighted.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2 FEATURE ENGINEERING COMPLETION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n✅ COMPLETED TASKS:\")\n",
    "print(f\"   1. ✅ Loaded engineered_student_data.csv\")\n",
    "print(f\"   2. ✅ Analyzed correlations for {len(numeric_features)} numeric features\")\n",
    "print(f\"   3. ✅ Analyzed associations for {len(categorical_features)} categorical features\")\n",
    "print(f\"   4. ✅ Created JSON mapping with numeric weights\")\n",
    "print(f\"   5. ✅ Applied numeric weights to categorical variables\")\n",
    "print(f\"   6. ✅ Performed sentiment analysis on {len(comment_fields)} comment fields\")\n",
    "print(f\"   7. ✅ Created comprehensive feature-engineered dataset\")\n",
    "\n",
    "print(f\"\\n📊 FINAL DATASET STATUS:\")\n",
    "print(f\"   • Original features: {df.shape[1]}\")\n",
    "print(f\"   • Final features: {df_weighted.shape[1]}\")\n",
    "print(f\"   • New features added: {df_weighted.shape[1] - df.shape[1]}\")\n",
    "print(f\"   • Weighted categorical features: {len([col for col in df_weighted.columns if col.endswith('_weighted')])}\")\n",
    "print(f\"   • Sentiment features: {len([col for col in df_weighted.columns if 'sentiment' in col])}\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT FILES:\")\n",
    "print(f\"   • Feature mappings: ../data/refined_data_for_model/feature_mappings.json\")\n",
    "print(f\"   • Engineered dataset: {output_path}\")\n",
    "\n",
    "print(f\"\\n🚀 READY FOR PREDICTION MODEL:\")\n",
    "print(f\"   • Dataset shape: {df_weighted.shape}\")\n",
    "print(f\"   • Target variable: 'risk' (medium/high)\")\n",
    "print(f\"   • Features ready for model training\")\n",
    "\n",
    "# Show column summary\n",
    "print(f\"\\n📋 FEATURE SUMMARY:\")\n",
    "original_features = [col for col in df_weighted.columns if not col.endswith('_weighted') and 'sentiment' not in col and col != 'risk_encoded']\n",
    "weighted_features = [col for col in df_weighted.columns if col.endswith('_weighted')]\n",
    "sentiment_features = [col for col in df_weighted.columns if 'sentiment' in col or 'text_length' in col or 'word_count' in col]\n",
    "\n",
    "print(f\"   • Original features: {len(original_features)}\")\n",
    "print(f\"   • Weighted categorical: {len(weighted_features)}\")\n",
    "print(f\"   • Sentiment/NLP features: {len(sentiment_features)}\")\n",
    "print(f\"   • Total engineered features: {len(weighted_features) + len(sentiment_features)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
